# Sprint 7 (AWS - DESAFIO FINAL) - Trilha de Data Engineering

### Introdu√ß√£o

Nesta s√©tima sprint da trilha de Data Engineering, avan√ßamos no desafio final com foco em ingest√£o e an√°lise de dados. Exploramos a ingest√£o de dados utilizando a API TMDB, realizamos atividades pr√°ticas com o Apache Spark e experimentamos o AWS Glue para integra√ß√£o e manipula√ß√£o de dados. Al√©m disso, conclu√≠mos o curso de Spark para refor√ßar nossos conhecimentos.

## Aprendizados

### **Ingest√£o de Dados com API TMDB**
- **API TMDB**: Aprendemos a realizar chamadas √† API do TMDB, capturando dados complementares de filmes e s√©ries. 
- Integra√ß√£o com AWS Lambda para automatizar a ingest√£o.
- Persist√™ncia dos dados no S3, organizando-os em arquivos JSON seguindo boas pr√°ticas de estrutura√ß√£o.

### **Apache Spark**
- **Contador de Palavras com Spark**: Criamos um script para realizar contagem de palavras utilizando as capacidades de processamento distribu√≠do do Apache Spark.
- Compreendemos conceitos como RDDs (Resilient Distributed Datasets), DataFrames e a√ß√µes/transforma√ß√µes no Spark.

### **AWS Glue**
- **AWS Glue Data Catalog**: Exploramos como criar e gerenciar cat√°logos de dados com o AWS Glue.
- Entendemos como o Glue interage com dados armazenados no S3 e como configur√°-lo para integra√ß√£o com outras ferramentas como o Athena.

### **Curso de Spark**
- Curso conclu√≠do sobre fundamentos e aplica√ß√µes do Apache Spark, consolidando habilidades para trabalhar com grandes volumes de dados.

## Desafios

### **Desafio Final**
Dando continuidade ao desafio iniciado na Sprint 6, nesta etapa, focamos na ingest√£o de dados externos e complementares aos dados de filmes e s√©ries:
- **Ingest√£o pela API TMDB**:
  - Consumimos dados utilizando AWS Lambda.
  - Persistimos os resultados no S3 em arquivos JSON organizados por dia de processamento.
  - Agrupamos os registros de forma otimizada, com no m√°ximo 100 por arquivo.
- **An√°lise de Dados**:
  - Identifica√ß√£o de rela√ß√µes entre custo e receita para os 5 melhores e 5 piores filmes dos g√™neros com√©dia e anima√ß√£o.
  - Prepara√ß√£o para futuras an√°lises mais aprofundadas no Data Lake.

- [üìÅDesafio](../sprint_7/desafio)

## Exerc√≠cios

- **Exerc√≠cio 1: Ingest√£o pela API TMDB**:
  
- **Exerc√≠cio 2: Contador de Palavras com Spark**:
  - Desenvolver um script que utiliza o Apache Spark para realizar contagem de palavras.
  - Implementa√ß√£o e execu√ß√£o localmente.

- **Exerc√≠cio 3: AWS Glue Data Catalog**:
  - Configurar e criar um Data Catalog utilizando o AWS Glue.
  - Explora√ß√£o das tabelas no cat√°logo para integra√ß√£o com outras ferramentas.

### Confira os tr√™s exerc√≠cios abaixo:

[üìÅExercicio-1_API_TMBD](../sprint_7/exercicios/README_api_tmdb.md)

[üìÅExercicio-2_Spark_Word_Count](../sprint_7/exercicios/exercicio_spark/)

[üìÅExercicio-3_AWS_Glue](../sprint_7/exercicios/README_exec_lab-glue.md)

## Conclus√£o

A Sprint 7 consolidou conhecimentos fundamentais para o desafio final, como ingest√£o de dados via API, uso de AWS Lambda, Spark e Glue. Essas pr√°ticas refor√ßaram nossa capacidade de lidar com dados em larga escala e de automatizar processos essenciais para um Data Lake. Seguimos bem preparados para as pr√≥ximas etapas.


